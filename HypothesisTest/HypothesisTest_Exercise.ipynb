{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1de19b2f",
   "metadata": {},
   "source": [
    "# Hypothesis test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3465f40-0d8a-44fc-92b5-3f0a262f0b52",
   "metadata": {},
   "source": [
    "Import delle librerie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97385693",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uproot\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy import optimize, fmin, stats\n",
    "from scipy.interpolate import interp1d\n",
    "from matplotlib import *\n",
    "from mpl_toolkits.mplot3d import Axes3D\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12379b61",
   "metadata": {},
   "source": [
    "Recupero delle informazioni e degli istogrammi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5522dec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getHistoInfo(fileName, histoName):\n",
    "    \"\"\"\n",
    "    Simple function that just open root file and retun numpy list\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    fileName : str\n",
    "        The name of file\n",
    "    histoName : str\n",
    "        The name of histogram\n",
    "    \n",
    "    Returns\n",
    "    ----------\n",
    "    dim-2 numpy array (bin content, bin edge)\n",
    "        \n",
    "    \"\"\"\n",
    "    file_ = uproot.open(fileName)\n",
    "    histo = file_[histoName].to_numpy()\n",
    "    return histo\n",
    "\n",
    "def getEvents(histo, lumi, min_, max_, isData=False):\n",
    "    \"\"\"\n",
    "    Return yields and bin arrays in a given range\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    histo : \n",
    "        dim-2 numpy array of histogram\n",
    "    lumi : double\n",
    "        luminosity\n",
    "    min_, max_ : double\n",
    "        minimum and maximum of interval\n",
    "    isData : bool\n",
    "        If True lumi is not considered\n",
    "    \n",
    "    Returns\n",
    "    ----------\n",
    "    Yields and bin numpy arrays in a given interval\n",
    "        \n",
    "    \"\"\"\n",
    "    mask_bin = (histo[1] >=min_) & (histo[1] <=max_)\n",
    "    mask_sel = (histo[1][:-1] >=min_) & (histo[1][:-1] <max_)\n",
    "\n",
    "    yields = histo[0][mask_sel]\n",
    "    if not isData: yields = yields * lumi\n",
    "    bins = histo[1][mask_bin]\n",
    "\n",
    "    return yields, bins\n",
    "\n",
    "def plotStack(signalHisto, bkgHisto, dataHisto, lumi, min_, max_,\n",
    "             labelExp = 'ATLAS Open Data', colors = ['blue','red'], text = 'ATLAS' ):\n",
    "\n",
    "    signal_yield, bins = getEvents(signalHisto, lumi, min_, max_)\n",
    "    bkg_yield = getEvents(bkgHisto, lumi, min_, max_)[0]\n",
    "    data_yield = getEvents(dataHisto, lumi, min_, max_, isData=True)[0]\n",
    "\n",
    "    #print(bins)\n",
    "    stack_w = np.column_stack((bkg_yield, signal_yield))\n",
    "    stack = np.column_stack((bins[:-1], bins[:-1]))\n",
    "\n",
    "\n",
    "    #Plot stack\n",
    "    labels=['Bkg', 'Higgs']\n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "    fig.set_size_inches((7,7))\n",
    "\n",
    "    bin_centres =  (bins[1:] + bins[:-1]) / 2\n",
    "    err = np.sqrt(data_yield)\n",
    "\n",
    "    ax.errorbar(bin_centres, data_yield, yerr=err, fmt='o', color='black', label='Data')\n",
    "    ax.hist(stack,  label=labels, stacked=True, bins=bins, weights = stack_w, color=colors)\n",
    "    maxY=ax.get_ylim()[1]*1.5\n",
    "    ax.set_ylabel(r\"Events\", loc=\"top\", fontsize=15)\n",
    "    ax.set_xlabel(r\"$m_{4l}$ [GeV]\", loc=\"right\", fontsize=15)\n",
    "    ax.tick_params(which=\"both\", direction=\"in\", length=6, width=1)\n",
    "    ax.set_ylim(0, maxY)\n",
    "    ax.text(min_, maxY*0.95, labelExp, weight=\"bold\",fontsize=15)\n",
    "    #ax.text(min_, maxY*0.85, r\"$\\sqrt{s}$\" + \" = 13 TeV,\" + \" $\\int$Ldt = \" + \" 10 fb\" + r\"$^{-1}$\",fontsize=15)\n",
    "    if 'ATLAS' in  text: ax.text(min_, maxY*0.85, r\"$\\sqrt{s}$\" + \" = 13 TeV,\" + \" $\\int$Ldt = \" + \" 10 fb\" + r\"$^{-1}$\",fontsize=15)\n",
    "    if 'CMS' in  text: ax.text(min_, maxY*0.85, r\"$\\sqrt{s}$\" + \" = 8 TeV,\" + \" $\\int$Ldt = \" + \" 11.6 fb\" + r\"$^{-1}$\",fontsize=15)\n",
    "\n",
    "    ax.legend(fontsize=15, frameon=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cff87fc2-d0f9-4c49-9702-58edf5c4e711",
   "metadata": {},
   "source": [
    "Recuperiamo le informazioni sull'istogramma `mass_four_lep` per le simulazioni MC di segnale e fondo, e per i dati. La luminosità integrata corrisponde a 10 fb$^{.1}$. Usiamo la funzione `plotStack` per visualizzare gli istogrammi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf021c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "histoName = 'mass_four_lep'\n",
    "lumi = 10060\n",
    "\n",
    "signalHisto = getHistoInfo('inputH4lep/Higgs.root', histoName)\n",
    "dataHisto = getHistoInfo('inputH4lep/data.root', histoName)\n",
    "bkgHisto = getHistoInfo('inputH4lep/Bkg.root', histoName)\n",
    "\n",
    "plotStack(signalHisto, bkgHisto, dataHisto, lumi, 80, 170)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6a7a57f-f008-4af1-84e2-4644f8a195fd",
   "metadata": {},
   "source": [
    "```{tip} Esercizio\n",
    ":class: show\n",
    "- Qual è il numero di eventi atteso dalle simulazioni e osservato nei dati?\n",
    "- Sapreste calcolare la significatività?\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac90479c-f3f3-46ed-b2ba-1b8840214e5c",
   "metadata": {},
   "source": [
    "```{admonition} Suggerimento\n",
    ":class: dropdown\n",
    "Usate l'output di `getHistoInfo`. Il primo elemento dell'array che torna la funzione contiene le yields.\n",
    ".\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a7ceb5d",
   "metadata": {},
   "source": [
    "## Hypothesis testing (no systematics, one POI)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d79a2aa7-c71d-4027-b0e6-0b98385c7301",
   "metadata": {},
   "source": [
    "```{tip} Esercizio\n",
    ":class: show\n",
    "Implementare il test d'ipotesi. Scrivere la negative log likelihood in ipotesi poissoniana, a partire dagli array contenenti gli eventi di segnale e fondo MC e i dati osservati. Si assuma:\n",
    "- nessuna sistematica\n",
    "- un unico parametro di interesse, $\\hat{\\mu}$\n",
    "\n",
    "Il likelihood ratio:\n",
    "\n",
    "$$\n",
    "\\lambda(\\mu) = \\frac{ L(\\mu,\n",
    "\\hat{\\hat{\\vec{\\theta}}}) } {L(\\hat{\\mu}, \\hat{\\vec{\\theta}}) } \\;\n",
    "$$\n",
    "\n",
    "Diventa quindi dipendente solo da $\\hat{\\mu}$ ($\\vec{\\theta}$ è il vettore dei nuisance parameters):\n",
    "$$\n",
    "\\lambda(\\mu) = \\frac{ L(\\mu)} {L(\\hat{\\mu})} \\;\n",
    "$$\n",
    "\n",
    "Ricordiamo che $\\mu$ è il valore del parametro nell'ipotesi da testare. Quanto vale nel caso di una scoperta?\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "049ce5b9-e458-46ac-980e-84d1d3ce82f6",
   "metadata": {},
   "source": [
    "```{admonition} Suggerimenti\n",
    ":class: dropdown\n",
    "\n",
    "- Ricordatevi che `numpy` vi permette di fare operazioni tra array elemento per elemento.\n",
    "Non c'è bisogno di fare loop!\n",
    "- `LikelihoodScan` è il metodo che vi permette di eseguire a 'mano' un fit, ossia di trovare il best fit del parametro di interesse. Vi serve se volete conoscere la likelihood del denominatore!\n",
    "- `ComputeLikelihood` è il metodo che calcola il valore della likelihood, **dato** un valore di $\\mu$\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d8d911a",
   "metadata": {},
   "source": [
    "Di seguito le funzioni da implementare per il Likelihood Ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "852f1ed5-13a4-4079-949d-be0c5455e572",
   "metadata": {},
   "source": [
    "### Funzioni per implemenatare il LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d31b72cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPoisson(expected, observed):\n",
    "    '''\n",
    "    Implement log Poisson when expected and observed values are given \n",
    "    '''\n",
    "    #implementazione della poissoniana\n",
    "    #poisson = ?\n",
    "    #return   ???\n",
    "\n",
    "def computeLikelihood(sig, bkg, data, mu):\n",
    "    \n",
    "    \"\"\"\n",
    "    implement negative log likelihood for each mu value\n",
    "          \n",
    "    Parameters\n",
    "    ----------\n",
    "    sig, bkg, data : \n",
    "         numpy array of yields for signal, bkg and data\n",
    "    mu : double\n",
    "        your parameter of interests\n",
    " \n",
    "    Returns\n",
    "    ----------\n",
    "    negative log likelihood\n",
    "    \"\"\"    \n",
    "\n",
    "\n",
    "    #nota: bins non vi serve! Ignoratelo\n",
    "    \n",
    "    #Costruite il valore expected e observed\n",
    "    #expected = ?\n",
    "    #observed = ?\n",
    "\n",
    "    #Questo è il vettore delle nll per ogni valore dei bin dell'istogramma\n",
    "    #nll_i = getPoisson(expected, observed)\n",
    "\n",
    "    #Come si ottiene la nll totale?\n",
    "    #nll = ?\n",
    "    return nll\n",
    "    \n",
    "def getLikelihoodRatio(l_num, l_den):\n",
    "    \n",
    "    #Costruite il likelihood ratio\n",
    "    #return ?\n",
    "\n",
    "def LikelihoodScan(parName, mu_interval, n_scan, \n",
    "                   sig, bkg, data,\n",
    "                   printGraph=True, append = ''):\n",
    "    \n",
    "    \"\"\"\n",
    "    1D - Likeilihood fit for 1 parameter\n",
    "          \n",
    "    Parameters\n",
    "    ----------\n",
    "    parName : string\n",
    "         name of parameter\n",
    "    mu_interval : double\n",
    "        size 2 array of min and max parameter\n",
    "    n_scan : int\n",
    "        Number of parameter value to be scanned\n",
    "    sig, bkg, data : \n",
    "         numpy array of yields for signal, bkg and data\n",
    "\n",
    "    printGraph: bool\n",
    "        draw likelihood as function of parameter\n",
    "        \n",
    "    Returns\n",
    "    ----------\n",
    "    mu_hat, mu_doen, mu_up : double\n",
    "        Best fitted value with its down and up error\n",
    "    graphPoints : array\n",
    "        2D array containing x and y points\n",
    "    \"\"\"    \n",
    "    \n",
    "    mu_min, mu_max = mu_interval[0], mu_interval[1]\n",
    "    \n",
    "    #Quanti step ha il fit?\n",
    "    #step = ??????\n",
    "    \n",
    "    #Array contenente i mu e il corrispondente valore della likelihood\n",
    "    tmp_mu = []\n",
    "    nll_tmp_mu =[]\n",
    "    \n",
    "    #Inizio del loop\n",
    "    for i in range(n_scan):\n",
    "\n",
    "        #Quanto vale il valore i-esimo di mu?\n",
    "        #mu_i = ?\n",
    "        tmp_mu.append(mu_i)\n",
    "        nll_tmp_mu.append(computeLikelihood(sig, bkg, data, mu_i))\n",
    "    \n",
    "\n",
    "    #Disegna il grafico nll vs mu, trova il minimo (best fit) con gli errori\n",
    "    plt.plot(tmp_mu, nll_tmp_mu)\n",
    "    plt.xlabel(parName,fontsize=15,loc=\"right\")\n",
    "    plt.ylabel('-nll',fontsize=15,loc=\"top\")\n",
    "\n",
    "    #Finding minima and errors\n",
    "    f_linear  = interp1d(tmp_mu, nll_tmp_mu,kind='quadratic')    \n",
    "    nll_min = min(f_linear(tmp_mu))\n",
    "    mu_hat = tmp_mu[np.argmin(f_linear(tmp_mu))]\n",
    "\n",
    "    points = np.transpose(np.array([tmp_mu, nll_tmp_mu]))\n",
    "    minimum = min(points, key=lambda point: point[1])\n",
    "    print(minimum)\n",
    "    # to find the roots, we need to supply a starting value\n",
    "    # because there are more than 1 root in our range, we need \n",
    "    # to supply multiple starting values.  They should be \n",
    "    # fairly close to the actual root\n",
    "    f2_linear = lambda tmp_mu: f_linear(tmp_mu) - nll_min - 0.5\n",
    "    mu_err_down, mu_err_up =  optimize.newton(f2_linear, mu_hat*0.9) , optimize.newton(f2_linear, mu_hat*1.1) \n",
    "\n",
    "    plt.vlines(x=mu_err_down, ymin=nll_min, ymax=nll_min + 0.5, color=\"red\", linestyle='dotted')\n",
    "    plt.vlines(x=mu_err_up, ymin=nll_min, ymax=nll_min + 0.5, color=\"red\", linestyle='dotted')\n",
    "    plt.hlines(nll_min, xmin=mu_err_down, xmax=mu_err_up, color=\"red\", linestyle='dotted')\n",
    "\n",
    "\n",
    "    return mu_hat, mu_err_up - mu_hat, mu_hat - mu_err_down, [tmp_mu, nll_tmp_mu]\n",
    "    #return mu_hat,0,0\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f06dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_ = 80\n",
    "max_ = 170\n",
    "\n",
    "#Implementare mu_range e n_scan\n",
    "#mu_range = ???\n",
    "#n_scan = ??\n",
    "\n",
    "#Recuperate le yields dai file\n",
    "signal_yield, bins = getEvents(signalHisto, lumi, min_, max_)\n",
    "bkg_yield = getEvents(bkgHisto, lumi, min_, max_)[0]\n",
    "data_yield = getEvents(dataHisto, lumi, min_, max_, isData=True)[0]\n",
    "\n",
    "\n",
    "##mu_hat, mu_up, mu_down, graph_points = LikelihoodScan(????)\n",
    "\n",
    "print (f'Found best mu: {mu_hat} + {mu_up}  -  {mu_down}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ac229b8",
   "metadata": {},
   "source": [
    "### Profile Likelihood ratio per la scoperta\n",
    "\n",
    "Siamo pronti per calcolare il nostro profile likelihood ratio nel caso di una scoperta, che è definito come.\n",
    "\n",
    "\n",
    "$q_0 = -2 ln \\lambda (0)$\n",
    "\n",
    "$\\lambda (0) = \\frac {L(0)} {L(\\hat{\\mu}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f743fd4",
   "metadata": {},
   "source": [
    "#### Fit di $\\mu$\n",
    "\n",
    "E' il momento di trovare il  best $\\mu$, $\\hat{\\mu}$, con i suoi errori. In quali valori del parametro si deve fare il fit? E quante iterazioni?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d2d182-9aa4-4365-967a-255cf9bc5626",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_ = 80\n",
    "max_ = 170\n",
    "#mu_range = ????\n",
    "#n_scan = ????\n",
    "\n",
    "\n",
    "signal_yield, bins = getEvents(signalHisto, lumi, min_, max_)\n",
    "bkg_yield = getEvents(bkgHisto, lumi, min_, max_)[0]\n",
    "data_yield = getEvents(dataHisto, lumi, min_, max_, isData=True)[0]\n",
    "\n",
    "\n",
    "#mu_hat, mu_up, mu_down, graph_points = LikelihoodScan(????)\n",
    "\n",
    "print (f'Found best mu: {mu_hat} + {mu_up}  -  {mu_down}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdc99c90-62ec-44ef-a0b8-d80c75702eed",
   "metadata": {},
   "source": [
    "```{admonition} Suggerimenti\n",
    ":class: dropdown\n",
    "\n",
    "- Userete `ComputeLikelihood` per costruire il numeratore ed il denominatore. Quali sono i valori di mu che devo usare nei due casi?\n",
    "- Come si calcola la significatività a partire dal valore del likelihood ratio?\n",
    "- Sapreste calcolare il p-value, nota la significatività? Utilizzare la funzione `stats.norm.sf` di `scipy`\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d8a009",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Le negative log likelihood nelle due ipotesi\n",
    "#nll_0 = computeLikelihood(????)\n",
    "#nll_mu = computeLikelihood(????)\n",
    "\n",
    "#Il valore del likelihood ratio\n",
    "#q0 = round(chefunzione????? , 3)\n",
    "\n",
    "#Significatività\n",
    "#sig_0 = round( COSAMETTOQUI? , 4)\n",
    "#p_value = round(??? , 4)\n",
    "\n",
    "print('Testing bkg only hypothesis')\n",
    "print('================================')\n",
    "print(f'nll_0: {nll_0}')\n",
    "print(f'nll_mu: {nll_mu}')\n",
    "\n",
    "print(f'Likelihood ratio: {q0}')\n",
    "print(f'Found significance {sig_0} for mu: {mu_hat} corresponding to a p-value of {p_value}')\n",
    "print('================================')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "581d9668",
   "metadata": {},
   "source": [
    "### Asimov dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57c61a9d-62f8-4cff-af77-daa7b8390907",
   "metadata": {},
   "source": [
    "```{tip} Esercizio\n",
    ":class: show\n",
    "Implementare il likelihood ratio per calcolare la significatività attesa con i dataset a disposizione utilizzando un dataset di Asimov\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd2300a6-0bcd-4d30-8094-0206136f2737",
   "metadata": {},
   "source": [
    "```{admonition} Suggerimenti\n",
    ":class: dropdown\n",
    "\n",
    "L'Asimov dataset permette di ottenere la significatività attesa senza generare N pseudoesperimenti. Si definisce come il dataset il cui valore osservato nei dati corrisponde a quello atteso, quindi per ogni bin dell'isrogramma\n",
    "\n",
    "$$\n",
    "n_{i,{\\rm A}} & = & E[n_i] = \\nu_i\n",
    "= \\mu^{\\prime} s_i(\\vec{\\theta}) + b_i(\\vec{\\theta}) \n",
    "$$\n",
    "\n",
    "Quindi: \n",
    "- Costruite opportunamente i dataset che vi servono (simulazione e dati)\n",
    "- Non avete bisogno di fittare $\\hat{\\mu}$, o meglio, quanto vale nel dataset di Asimov?\n",
    "- Da un punto di vista tecnico avete già tutte le funzioni implementate\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ffa524-405e-4d0f-b62e-4cba94371d45",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "###asimov_dset = ????\n",
    "#mu_A = ???\n",
    "##nll_0A = ???\n",
    "##nll_muA = ????\n",
    "##q0_A = round(getLikelihoodRatio(???) , 3)\n",
    "##sig_0A = round( ???, 4)\n",
    "\n",
    "\n",
    "print('Testing bkg only hypothesis for Asimov Dataset')\n",
    "print('================================')\n",
    "print(f'nll_0: {nll_0A}')\n",
    "print(f'nll_mu: {nll_muA}')\n",
    "print(f'Likelihood ratio: {q0_A}')\n",
    "print(f'Found expected significance {sig_0A} for mu: {mu_A}')\n",
    "print('================================')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e62cc2fa",
   "metadata": {},
   "source": [
    "\n",
    "### Cut and count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "421ce2f0-ade5-455e-9275-db5d1c67d63f",
   "metadata": {},
   "source": [
    "```{tip} Esercizio\n",
    ":class: show\n",
    "Implementare il test di ipotesi nel caso di approccio 'Cut and Count', ossia anzichè utilizzare una distribuzione di una data variabile (stiamo usando la massa), utilizziamo solo il numero di eventi. Cambia rispetto al precedente?\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4865ff88-b85f-4166-a9aa-a4bb8f444e66",
   "metadata": {},
   "source": [
    "```{admonition} Suggerimenti\n",
    ":class: dropdown\n",
    "\n",
    "- Vi basta quindi il numero di eventi totali per ogni distribuzione, utilizzate le funzioni di  `numpy` \n",
    "- Il resto del test è esattamente lo stesso!\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae2d151e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "min_=110\n",
    "max_=140\n",
    "\n",
    "#signal_cc = ?? \n",
    "#bkg_cc = ??\n",
    "#data_cc = ??\n",
    "\n",
    "print('Doing cut and count fit')\n",
    "print('================================')\n",
    "print(f'Signal {signal_cc}')\n",
    "print(f'Bkg {bkg_cc}')\n",
    "print(f'Data {data_cc}')\n",
    "print('================================\\n')\n",
    "\n",
    "\n",
    "##mu_hat, mu_up, mu_down = LikelihoodScan(??)\n",
    "\n",
    "print (f'Found best mu: {mu_hat} + {mu_up}  -  {mu_down}\\n')\n",
    "\n",
    "#nll_0 = computeLikelihood(??)\n",
    "#nll_mu = computeLikelihood(???)\n",
    "#q0 = round(getLikelihoodRatio(???) , 3)\n",
    "#sig_0 = round( ???, 2)\n",
    "\n",
    "print('Testing bkg only hypothesis')\n",
    "print('================================')\n",
    "print(f'Likelihood ratio: {q0}')\n",
    "print(f'Found significance {sig_0} for mu: {mu_hat}')\n",
    "print('================================\\n')\n",
    "\n",
    "#asimov_cc =???\n",
    "#mu_A = ??\n",
    "#nll_0A = computeLikelihood(???)\n",
    "#nll_muA = ????\n",
    "#q0_A = rouund(????) , 3)\n",
    "#sig_0A = round( np.sqrt(q0_A), 2)\n",
    "\n",
    "\n",
    "print('Testing bkg only hypothesis for Asimov Dataset')\n",
    "print('================================')\n",
    "print(f'Likelihood ratio: {q0_A}')\n",
    "print(f'Found expected significance {sig_0A} for mu: {mu_A}')\n",
    "print('================================')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0942488f-9c13-4c78-b578-38e04aa2e891",
   "metadata": {},
   "source": [
    "## Hypothesis test with bkg normalization (Gaussian syst)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48916003-e406-4270-a428-649f24e53a58",
   "metadata": {},
   "source": [
    "```{tip} Esercizio\n",
    ":class: show\n",
    "Si assuma che la nostra distribuzione del fondo sia nota con una data incertezza $\\sigma_B$, che ha l'effetto di shiftare la distribuzione della massa (verso l'alto o il basso). Supponiamo che il nostro nuisance parameter ha una distribuzione Gaussiana del tipo\n",
    "\n",
    "$\\mathcal{L} = Poisson(N | \\mu s + b(1 + \\sigma_B\\tau)) * Gaussian(0|\\tau, 1)$\n",
    "\n",
    "Si fissi  $\\sigma_B$ ad un dato valore (ad esempio 10%), e $\\tau$ è il nuisance parameter da stimare, scelto in modo tale che valori $\\pm 1$ corssipondono all'incertezza nominale $\\sigma_B$\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7081ef4-638f-4d29-9b73-8e0d74ef9d43",
   "metadata": {},
   "source": [
    "Fissiamo $\\sigma_B$ e visualizziamo le variazioni del fonto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "624fc69a-95fe-4498-bdb0-9b491050fddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_ = 80\n",
    "max_ = 170\n",
    "\n",
    "#sigma = ???\n",
    "\n",
    "signal_yield, bins = getEvents(signalHisto, lumi, min_, max_)\n",
    "bkg_yield = getEvents(bkgHisto, lumi, min_, max_)[0]\n",
    "data_yield = getEvents(dataHisto, lumi, min_, max_, isData=True)[0]\n",
    "\n",
    "bkg_up = bkg_yield*(1+sigma)\n",
    "bkg_down = bkg_yield*(1-sigma)\n",
    "\n",
    "plotStack(signalHisto, bkgHisto, dataHisto, lumi, min_, max_)\n",
    "\n",
    "plt.hist(bins[:-1] ,bins , weights=bkg_up, label='Bkg + $\\sigma$', color='green',histtype='step',linestyle='dashed',linewidth=2)\n",
    "plt.hist(bins[:-1] ,bins , weights=bkg_down, label='Bkg - $\\sigma$', color='yellow',histtype='step',linestyle='dashed' ,linewidth=2)\n",
    "\n",
    "plt.legend(fontsize=15, frameon=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a5ae3e5-841c-42f9-9aae-011a76575331",
   "metadata": {},
   "source": [
    "```{admonition} Suggerimenti\n",
    ":class: dropdown\n",
    "\n",
    "- Fissare $sigma_B$ ad un dato valore\n",
    "\n",
    "Le funzioni scritte sopra non vanno più bene, perchè? Non abbiamo più il solo POI, ma anche 1 nuisance parameter. Ricordiamoci che il rapporto è definito come \n",
    "\n",
    "$$\n",
    "\\lambda(\\mu) = \\frac{ L(\\mu,\n",
    "\\hat{\\hat{\\vec{\\theta}}}) } {L(\\hat{\\mu}, \\hat{\\vec{\\theta}}) } \\;\n",
    "$$\n",
    "\n",
    "Dunque abbiamo bisogno di fare due fit:\n",
    "- al numeratore, per avere il best fit di $\\tau$ fissato $\\mu$ (siamo sempre nel caso di scoperta quindi quanto vale $\\mu$?). Questo è sempre un fit 1D, abbiamo un parametro da stimare\n",
    "- al denominatore, per avere il best fit di $\\tau$ e $\\mu$. Occhio questo è un fit 2D! La minimizzazione va fatta insieme. Dobbiamo scrivere questa funzione\n",
    "\n",
    "Scriveremo quindi: \n",
    "- `computeLikelihood2D`: una funzione che calcola la negative log likelihood sommando il contributo della poissoniana e della gaussiana\n",
    "- `LikelihoodScan2D`: una funzione che minimizza contemporanemante $\\mu$ e $\\tau$\n",
    "- `LikelihoodScan1D`: sulla falsariga di quanto già fatto precedentemente per $\\mu$, questa volta però per $\\tau$\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cbc0bad-28b3-4c13-a404-4d24aba8313b",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0032682-7c4a-4682-9a05-dfcfb3d9e0e2",
   "metadata": {},
   "source": [
    "```{admonition} Suggerimento\n",
    ":class: dropdown\n",
    "\n",
    "- il numero di eventi atteso è leggermente diverso\n",
    "- `getPoisson` è quello già implementato\n",
    "- Va aggiunto il contributo della gaussiana\n",
    "- I pezzi vanno sommati insieme\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22604422-91d4-4dbd-9daf-bf5b380c0b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeLikelihood2D( sig, bkg, data, mu, tau, sigma):\n",
    "\n",
    "    \"\"\"\n",
    "    implement negative log likelihood for each mu value\n",
    "          \n",
    "    Parameters\n",
    "    ----------\n",
    "    sig, bkg, data : \n",
    "         numpy array of yields for signal, bkg and data\n",
    "    mu, tau : double\n",
    "        your parameters\n",
    "    sigma: double\n",
    "        bkg normalization\n",
    " \n",
    "    Returns\n",
    "    ----------\n",
    "    negative log likelihood\n",
    "    \"\"\"  \n",
    "    \n",
    "    #likelihoods implemented here\n",
    "    #expected = ??\n",
    "    #observed = ???\n",
    "\n",
    "    #nll_i = ?\n",
    "   \n",
    "    #Contributo del termine gaussiano\n",
    "    ##nll_gauss =  ???\n",
    "\n",
    "    #Quanto fa la likelihood totale?\n",
    "    #nll = ??\n",
    "   \n",
    "    return nll"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87025472-2b21-4e16-959e-57de87604e5b",
   "metadata": {},
   "source": [
    "```{admonition} Suggerimento\n",
    ":class: dropdown\n",
    "\n",
    "- Stavolta abbiamo un doppio loop, visto che sono due parametri! Ci metterà un pò non esagerate con lo scan\n",
    "\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d16525-f74d-4ae6-b531-08b2234640d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LikelihoodScan2D(parName, interval, n_scan, \n",
    "                    parName2, interval2, n_scan2, sigma,\n",
    "                    sig, bkg, data, \n",
    "                     \n",
    "                    printGraph=True, append = ''):\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    2D - Likelihood fit for 2 parameters\n",
    "          \n",
    "    Parameters\n",
    "    ----------\n",
    "    parName, parName2 : string\n",
    "         name of parameter\n",
    "    interval, interval2 : double\n",
    "        size 2 array of min and max parameter\n",
    "    n_scan, n_scan2 : int\n",
    "        Number of parameter value to be scanned\n",
    "    sigma: double\n",
    "        bkg normalization\n",
    "    sig, bkg, data : \n",
    "         numpy array of yields for signal, bkg and data\n",
    "    printGraph: bool\n",
    "        draw likelihood as function of parameter\n",
    "        \n",
    "    Returns\n",
    "    ----------\n",
    "    mu_hat, tau_hat, nll : double\n",
    "        Best fitted values and nll\n",
    "\n",
    "    \"\"\"    \n",
    "    mu_min, mu_max = interval[0], interval[1]\n",
    "    tau_min, tau_max = interval2[0], interval2[1]\n",
    "    step_mu = (mu_max - mu_min)/n_scan\n",
    "    step_tau = (tau_max - tau_min)/n_scan2\n",
    "\n",
    "    nll_tmp =[]\n",
    "    tmp_mu = []\n",
    "    tmp_tau = []\n",
    "   \n",
    "    ################################################################\n",
    "    ##Implementate il valore della likelihood per ogni mu e tau\n",
    "    ##QUI IL CODICE\n",
    "\n",
    "    ###############################################################\n",
    "\n",
    "\n",
    "    \n",
    "    points = np.transpose( np.array([tmp_mu, tmp_tau, nll_tmp]))\n",
    "    print(points.shape)\n",
    "    minimum = min(points, key=lambda point: point[2])\n",
    "\n",
    "    print (f'Minimum is: mu hat: {minimum[0]}, tau hat: {minimum[1]}, nll {minimum[2]}')\n",
    "    plt.hist2d(tmp_mu, tmp_tau, bins=100, weights=nll_tmp)\n",
    "    plt.plot(minimum[0],minimum[1],'ro') \n",
    "\n",
    "    return minimum[0], minimum[1], minimum[2]\n",
    "\n",
    "\n",
    "def LikelihoodScan1D(parName, tau_interval, n_scan, sigma,\n",
    "                    sig, bkg, data, mu,  \n",
    "                    printGraph=True, append = ''):\n",
    "    \n",
    "    tau_min, tau_max = tau_interval[0], tau_interval[1]\n",
    "    step = (tau_max - tau_min)/n_scan\n",
    "    nll_tmp_tau =[]\n",
    "    tmp_tau = []\n",
    "\n",
    "    ################################################################\n",
    "    ##Implementate il valore della likelihood per ogni mu e tau\n",
    "    ##QUI IL CODICE\n",
    "\n",
    "    ###############################################################\n",
    "   \n",
    "    \n",
    "    \n",
    "    #print(nll_tmp_mu)\n",
    "    plt.plot(tmp_tau, nll_tmp_tau)\n",
    "\n",
    "    #Finding minima and errors\n",
    "    f_linear  = interp1d(tmp_tau, nll_tmp_tau,kind='quadratic')    \n",
    "    nll_min = min(f_linear(tmp_tau))\n",
    "    tau_hat = tmp_tau[np.argmin(f_linear(tmp_tau))]\n",
    "\n",
    "    print('minimum in ', tau_hat, 'nll ', nll_min)\n",
    "    \n",
    "    return tau_hat #, tau_err_up - tau_hat, tau_hat - tau_err_down\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a498cbdb-8752-4264-a107-c2d042c91ceb",
   "metadata": {},
   "source": [
    "### PRL on observed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd2286a5-1b01-401b-9671-5850e8ea494d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mu_hat, tau_hat, nll_mu_tau  = LikelihoodScan2D(????)                                              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b55d3a-2d18-4121-b4ca-ed91dccde540",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tau_hat_hat = LikelihoodScan1D(????)\n",
    "print(tau_hat_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af6dd2fc-ed68-4bc7-ae68-fed2c7e3250d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#nll_0 = ??\n",
    "#nll_mu =??\n",
    "#q0 = ??\n",
    "#sig_0 =?? \n",
    "\n",
    "print('Testing bkg only hypothesis')\n",
    "print('================================')\n",
    "print(f'nll_0: {nll_0}')\n",
    "print(f'nll_mu: {nll_mu}')\n",
    "\n",
    "print(f'Likelihood ratio: {q0}')\n",
    "print(f'Found significance {sig_0} for mu: {mu_hat}')\n",
    "print('================================')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ca01a3f-455f-45a8-9040-a4fd5f345841",
   "metadata": {},
   "source": [
    "### PRL on Asimov"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf928fd4-996c-4ea0-89b7-93e522b01cdc",
   "metadata": {},
   "source": [
    "```{tip} Esercizio\n",
    ":class: show\n",
    "Quanto vale la significatività attesa?\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "379add14-4784-4fd3-96f6-4b593c0dd5e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "asimov_dset = ???\n",
    "mu_A = ????\n",
    "\n",
    "tau_hat_hat_A0 = ???\n",
    "\n",
    "print(tau_hat_hat_A0)\n",
    "\n",
    "\n",
    "nll_0A =??\n",
    "nll_muA =??\n",
    "q0_A = ??\n",
    "sig_0A = ??\n",
    "'''\n",
    "\n",
    "print('Testing bkg only hypothesis for Asimov Dataset')\n",
    "print('================================')\n",
    "print(f'nll_0: {nll_0A}')\n",
    "print(f'nll_mu: {nll_muA}')\n",
    "print(f'Likelihood ratio: {q0_A}')\n",
    "print(f'Found expected significance {sig_0A} for mu: {mu_A}')\n",
    "print('================================')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fad776c9-4fe5-47c1-88e0-4bad9d1499f9",
   "metadata": {},
   "source": [
    "## Combinazione di risultati\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cb714fa-bf64-4805-a7e3-5a5dbfe46c62",
   "metadata": {},
   "source": [
    "```{tip} Esercizio\n",
    ":class: show\n",
    "E' tempo di combinazione! Assumiamo che ATLAS e CMS vogliano combinare i loro risultati. Qual'è la likelihood combinata?\\n\n",
    "\n",
    "Tocca a voi scrivere tutto!(Ormai siete esperti)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2afa1a7a-c86d-475b-9a7c-5686184f65c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Recostruct Data distribution\n",
    "histoName = 'Higgs_mass'\n",
    "lumi_CMS = 1\n",
    "\n",
    "signalHistoCMS = getHistoInfo('CMS_input/CMS_signal.root', histoName)\n",
    "dataHistoCMS = getHistoInfo('CMS_input/CMS_data.root', histoName)\n",
    "bkgHistoCMS = getHistoInfo('CMS_input/CMS_bkg.root', histoName)\n",
    "\n",
    "plotStack(signalHistoCMS, bkgHistoCMS, dataHistoCMS, lumi_CMS, 70, 180, labelExp = 'CMS', colors=['green', 'yellow'], text='CMS')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e15cc2d2-8c5c-41aa-a5fb-ee6b4528c029",
   "metadata": {},
   "source": [
    "```{tip} Esercizio\n",
    ":class: show\n",
    "Riapplicate il test d'ipotesi nel caso di CMS. \n",
    "\n",
    "Quanto vale la significatività? Ve lo aspettavate?\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ecc40a3-4175-4cc0-8c42-397a871f2c1c",
   "metadata": {},
   "source": [
    "```{tip} Esercizio\n",
    ":class: show\n",
    "Scrivete la combinazione dei risultati di ATLAS e CMS\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4dad7bb-9dea-4484-b1d2-404e7e4cd794",
   "metadata": {},
   "source": [
    "```{admonition} Suggerimenti\n",
    ":class: dropdown\n",
    "\n",
    "Nel caso di una combinazione avrete:\n",
    "\n",
    "$$\n",
    "L_{Total} = L_{ATLAS} + L_{CMS}\n",
    "$$\n",
    "\n",
    "dove \n",
    "\n",
    "$$\n",
    "L_{ATLAS}(\\mu, \\vec{\\theta}) =\n",
    "\\prod_{j=1}^N \\frac{ (\\mu s_{j} +\n",
    "b_{j} )^{n_{j}} }{ n_{j}! }\n",
    "e^{- (\\mu s_{j} + b_{j}) } \\;\n",
    "L_{CMS}(\\mu, \\vec{\\theta}) =\n",
    "\\prod_{i=1}^N \\frac{ (\\mu s_{j} +\n",
    "b_{i} )^{n_{i}} }{ n_{i}! }\n",
    "e^{- (\\mu s_{i} + b_{i}) } \\;\n",
    "$$\n",
    "\n",
    "Notate i due indici diversi sui quali si fa la sommatoria (istogrammi diversi!)\n",
    "\n",
    "Le nostre 'solite' funzioni implementeranno quindi una somma. Stavolta dovrete passare le yields MC e dati per ATLAS e CMS, modificate di coseguenza le funzioni.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bac6a65c-453b-4c39-b831-3211a50d0304",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ace5dbf-1e39-45da-b0af-31b72eaee7b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def computeLikelihoodComb(sig, bkg, data, \n",
    "                          sig2, bkg2, data2,\n",
    "                          mu, bins):\n",
    "\n",
    "    ###############\n",
    "    #VOSTRO CODICE\n",
    "    ###############   \n",
    "    \n",
    "    \n",
    "    return nll + nll_2\n",
    "    \n",
    "def getLikelihoodRatio(l_num, l_den):\n",
    "\n",
    "    ###############\n",
    "    #VOSTRO CODICE\n",
    "    ###############   \n",
    "def LikelihoodScanComb(parName, mu_interval, n_scan, \n",
    "                   sig, bkg, data, \n",
    "                   sig2, bkg2, data2,                   \n",
    "                   bins,\n",
    "                   printGraph=True, append = ''):\n",
    "\n",
    "    ###############\n",
    "    #VOSTRO CODICE\n",
    "    ###############   \n",
    "    \n",
    "\n",
    "    #Finding minima and errors\n",
    "    f_linear  = interp1d(tmp_mu, nll_tmp_mu,kind='quadratic')    \n",
    "    nll_min = min(f_linear(tmp_mu))\n",
    "    mu_hat = tmp_mu[np.argmin(f_linear(tmp_mu))]\n",
    "\n",
    "    points = np.transpose(np.array([tmp_mu, nll_tmp_mu]))\n",
    "    minimum = min(points, key=lambda point: point[1])\n",
    "    print(minimum)\n",
    "    # to find the roots, we need to supply a starting value\n",
    "    # because there are more than 1 root in our range, we need \n",
    "    # to supply multiple starting values.  They should be \n",
    "    # fairly close to the actual root\n",
    "    f2_linear = lambda tmp_mu: f_linear(tmp_mu) - nll_min - 0.5\n",
    "    mu_err_down, mu_err_up =  optimize.newton(f2_linear, mu_hat*0.9) , optimize.newton(f2_linear, mu_hat*1.1) \n",
    "\n",
    "    plt.vlines(x=mu_err_down, ymin=nll_min, ymax=nll_min + 0.5, color=\"red\", linestyle='dotted')\n",
    "    plt.vlines(x=mu_err_up, ymin=nll_min, ymax=nll_min + 0.5, color=\"red\", linestyle='dotted')\n",
    "    plt.hlines(nll_min, xmin=mu_err_down, xmax=mu_err_up, color=\"red\", linestyle='dotted')\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    return mu_hat, mu_err_up - mu_hat, mu_hat - mu_err_down\n",
    "    #return mu_hat,0,0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "999437a5-3f21-4538-8ee6-ca33df624483",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rootEnv",
   "language": "python",
   "name": "rootenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
